---
systemd:
  units:
    - name: docker.service
      enable: false
      mask: true

    - name: containerd.service
      enable: false
      mask: true

    - name: update-engine.service
      enable: false
      mask: true

    - name: update-engine-stub.service
      enable: false
      mask: true

    - name: install-etcd.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/etcd
        [Service]
        Type=oneshot
        Environment=IMAGE={{.etcd_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/etcdctl /opt/bin/etcdctl
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/etcd
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-fleet.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/fleetd
        [Service]
        Type=oneshot
        Environment=IMAGE={{.fleet_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/fleetctl /opt/bin/fleetctl
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/fleetd
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-rkt.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/rkt
        [Service]
        Type=oneshot
        Environment=IMAGE={{.rkt_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/rkt /opt/bin/rkt
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/rkt
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-cni.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/host-local
        [Service]
        Type=oneshot
        Environment=IMAGE={{.cni_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/cnitool /opt/bin/cnitool
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/host-local
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-hyperkube.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/hyperkube
        [Service]
        Type=oneshot
        Environment=IMAGE={{.hyperkube_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/hyperkube /opt/bin/kubectl
        ExecReload=-/bin/rm -v /opt/rootfs/hyperkube
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: installs.target
      contents: |
        [Unit]
        Requires=install-cni.service
        After=install-cni.service
        Requires=install-fleet.service
        After=install-fleet.service
        Requires=install-etcd.service
        After=install-etcd.service
        Requires=install-rkt.service
        After=install-rkt.service
        Requires=install-hyperkube.service
        After=install-hyperkube.service

    - name: rkt-api.service
      enable: true
      contents: |
        [Unit]
        After=install-rkt.service

        [Service]
        LimitNOFILE=65826
        ExecStart=/opt/rootfs/usr/bin/rkt api-service
        Restart=always
        RestartSec=2

        [Install]
        RequiredBy=multi-user.target

    - name: systemd-timesyncd.service
      enable: true

    - name: ntpd.service
      enable: false

    - name: etcd.service
      mask: true
      enable: false

    - name: etcd2.service
      mask: true
      enable: false

    - name: vault-token-client@etcd-kubernetes.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i client
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-kubelet@kubernetes.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i kubelet
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-kube-apiserver@kubernetes.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i kube-apiserver
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-peer@etcd-fleet.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i peer
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-client@etcd-fleet.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i client
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-client@etcd-kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/client.token
        ExecStart=/opt/bin/vault-pki-issue %i client
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-kubelet@kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/kubelet.token
        ExecStart=/opt/bin/vault-pki-issue %i kubelet
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-kube-apiserver@kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/kube-apiserver.token
        ExecStart=/opt/bin/vault-pki-issue %i kube-apiserver
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-secret-service-accounts@kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/kube-apiserver.token
        ExecStart=/opt/bin/vault-secret %i service-accounts
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-peer@etcd-fleet.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/peer.token
        ExecStart=/opt/bin/vault-pki-issue %i peer
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-client@etcd-fleet.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/client.token
        ExecStart=/opt/bin/vault-pki-issue %i client
        RestartSec={{.vault_polling_sec}}
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: etcd3@kubernetes.service
      enable: true
      contents: |
        [Unit]
        After=install-etcd.service
        Conflicts=etcd.service etcd2.service

        [Service]
        Type=notify
        ExecStartPre=/bin/ls -l \
          /etc/vault.d/etcd-%i/client.issuing_ca
        ExecStart=/opt/rootfs/usr/bin/etcd \
          gateway start \
          --endpoints={{ .kubernetes_etcd_member_client_uri_list }} \
          --listen-addr="127.0.0.1:{{.kubernetes_etcd_client_port}}" \
          --trusted-ca-file="/etc/vault.d/etcd-%i/client.issuing_ca"
        RestartSec=10s
        Restart=on-failure
        LimitNOFILE=65826
        [Install]
        WantedBy=multi-user.target

    - name: etcd3@fleet.service
      enable: true
      contents: |
        [Unit]
        After=install-etcd.service
        Conflicts=etcd.service etcd2.service

        [Service]
        Type=notify
        EnvironmentFile=/etc/etcd-%i.env
        ExecStartPre=/bin/ls -l \
          /etc/vault.d/etcd-%i/client.certificate \
          /etc/vault.d/etcd-%i/client.private_key \
          /etc/vault.d/etcd-%i/client.issuing_ca \
          /etc/vault.d/etcd-%i/peer.certificate \
          /etc/vault.d/etcd-%i/peer.private_key \
          /etc/vault.d/etcd-%i/peer.issuing_ca
        ExecStart=/opt/rootfs/usr/bin/etcd \
          --cert-file /etc/vault.d/etcd-%i/client.certificate \
          --key-file /etc/vault.d/etcd-%i/client.private_key \
          --trusted-ca-file /etc/vault.d/etcd-%i/client.issuing_ca \
          --client-cert-auth \
          \
          --peer-cert-file /etc/vault.d/etcd-%i/peer.certificate \
          --peer-key-file /etc/vault.d/etcd-%i/peer.private_key \
          --peer-trusted-ca-file /etc/vault.d/etcd-%i/peer.issuing_ca \
          --peer-client-cert-auth
        RestartSec=5s
        Restart=on-failure
        LimitNOFILE=65826
        [Install]
        WantedBy=multi-user.target

    - name: kube-apiserver.service
      enable: true
      contents: |
        [Unit]
        After=etcd3@kubernetes.service
        [Service]
        Environment=ETCDCTL_API=3
        ExecStartPre=/bin/ls -l \
          /etc/vault.d/kubernetes/kube-apiserver.certificate \
          /etc/vault.d/kubernetes/kube-apiserver.private_key \
          /etc/vault.d/kubernetes/kube-apiserver.issuing_ca \
          /etc/vault.d/kubernetes/kubelet.certificate \
          /etc/vault.d/kubernetes/kubelet.private_key \
          /etc/vault.d/kubernetes/kubelet.issuing_ca \
          /etc/vault.d/kubernetes/service-accounts.key \
          /etc/vault.d/etcd-kubernetes/client.certificate \
          /etc/vault.d/etcd-kubernetes/client.private_key \
          /etc/vault.d/etcd-kubernetes/client.issuing_ca
        ExecStartPre=/opt/bin/etcdctl3 --endpoints https://127.0.0.1:{{.kubernetes_etcd_client_port}} \
          --cacert=/etc/vault.d/etcd-kubernetes/client.issuing_ca \
          --cert=/etc/vault.d/etcd-kubernetes/client.certificate \
          --key=/etc/vault.d/etcd-kubernetes/client.private_key \
          endpoint status
        ExecStart=/opt/rootfs/hyperkube apiserver proxy \
          --advertise-address={{.network.ip}} \
          --insecure-bind-address=127.0.0.1 \
          --insecure-port={{.kubernetes_apiserver_insecure_port}} \
          --allow-privileged=true \
          --service-cluster-ip-range={{.kubernetes_service_cluster_ip_range}} \
          --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \
          --runtime-config=batch/v2alpha1 \
          --tls-ca-file=/etc/vault.d/kubernetes/kube-apiserver.issuing_ca \
          --tls-cert-file=/etc/vault.d/kubernetes/kube-apiserver.certificate \
          --tls-private-key-file=/etc/vault.d/kubernetes/kube-apiserver.private_key \
          --client-ca-file=/etc/vault.d/kubernetes/kube-apiserver.issuing_ca \
          --kubelet-certificate-authority=/etc/vault.d/kubernetes/kubelet.issuing_ca \
          --kubelet-client-certificate=/etc/vault.d/kubernetes/kubelet.certificate \
          --kubelet-client-key=/etc/vault.d/kubernetes/kubelet.private_key \
          --kubelet-https=true \
          --kubelet-preferred-address-types=InternalIP,LegacyHostIP,ExternalDNS,InternalDNS,Hostname \
          --service-account-key-file=/etc/vault.d/kubernetes/service-accounts.key \
          --service-account-lookup=true \
          --authorization-mode=AlwaysAllow \
          --anonymous-auth=false \
          --etcd-servers=https://127.0.0.1:{{.kubernetes_etcd_client_port}} \
          --etcd-cafile=/etc/vault.d/etcd-kubernetes/client.issuing_ca \
          --etcd-certfile=/etc/vault.d/etcd-kubernetes/client.certificate \
          --etcd-keyfile=/etc/vault.d/etcd-kubernetes/client.private_key
        Restart=always
        RestartSec=5s
        [Install]
        WantedBy=multi-user.target

    - name: kubelet.service
      enable: true
      contents: |
        [Unit]
        After=rkt-api.service
        Requires=rkt-api.service
        After=kube-apiserver.service
        [Service]
        ExecStartPre=/bin/ls -l \
          /etc/vault.d/kubernetes/kubelet.certificate \
          /etc/vault.d/kubernetes/kubelet.private_key \
          /etc/vault.d/kubernetes/kubelet.issuing_ca
        ExecStartPre=/bin/mkdir -pv /var/lib/kubelet/kubeconfig
        ExecStart=/opt/rootfs/hyperkube kubelet \
          --hairpin-mode=none \
          --non-masquerade-cidr={{.network.subnet}} \
          --network-plugin=cni \
          --cni-bin-dir=/opt/rootfs/usr/bin \
          --cni-conf-dir=/etc/rkt/net.d \
          --hostname-override={{.kubernetes_node_name}} \
          --node-ip={{.kubernetes_node_ip}} \
          --register-schedulable=false \
          --allow-privileged=true \
          --enable-custom-metrics \
          --api-servers=http://127.0.0.1:{{.kubernetes_apiserver_insecure_port}} \
          --node-labels=node=true \
          --cloud-provider="" \
          --container-runtime=rkt \
          --rkt-path=/opt/rootfs/usr/bin/rkt \
          --v=2 \
          --tls-cert-file=/etc/vault.d/kubernetes/kubelet.certificate \
          --tls-private-key-file=/etc/vault.d/kubernetes/kubelet.private_key \
          --client-ca-file=/etc/vault.d/kubernetes/kubelet.issuing_ca
        Restart=always
        RestartSec=5s
        [Install]
        WantedBy=multi-user.target

    - name: fleet.service
      enable: true
      dropins:
        - name: 10-cluster.conf
          contents: |
            [Unit]
            After=installs.target
            After=etcd3@fleet.service
            After=rkt-metadata.service
            [Service]
            EnvironmentFile=/etc/metadata.env
            ExecStartPre=/bin/ls -lL /opt/bin/rkt
            ExecStartPre=/opt/bin/etcdctl --no-sync --endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} ls
            ExecStart=
            ExecStart=/opt/rootfs/usr/bin/fleetd
            Restart=always
            RestartSec=10

    - name: lifecycle-ready.service
      enable: true
      contents: |
        [Unit]
        After=etcd3@kubernetes.service
        After=kubelet.service
        [Service]
        Type=oneshot
        ExecStart=/opt/bin/lifecycle-ready
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: lifecycle-update.service
      enable: true
      contents: |
        [Unit]
        After=etcd3@vault.service
        After=etcd3@fleet.service
        After=etcd3@kubernetes.service
        After=kubelet.service
        After=lifecycle-ready.service
        [Service]
        EnvironmentFile=/etc/metadata.env
        ExecStart=/opt/bin/lifecycle-update
        Restart=always
        RestartSec={{.lifecycle_update_polling_sec}}
        [Install]
        WantedBy=multi-user.target

    - name: rkt-gc.service
      enable: true
      dropins:
        - name: 10-rkt.conf
          contents: |
            [Service]
            ExecStart=
            ExecStartPre=-/opt/rootfs/usr/bin/rkt image gc --grace-period=1h
            ExecStart=/opt/rootfs/usr/bin/rkt gc --grace-period=0s

    - name: rkt-gc.timer
      enable: true
      dropins:
        - name: 10-rkt.conf
          contents: |
            [Service]
            OnActiveSec=
            OnActiveSec=5min
            OnUnitActiveSec=
            OnUnitActiveSec=10min

storage:
  files:
    - path: /etc/enjoliver
      filesystem: root
      mode: 0644
      contents:
        inline: |
          revision=1

    - path: /opt/rootfs/.keep
      filesystem: root
      mode: 0644

    - path: /etc/metadata.env
      filesystem: root
      mode: 0644
      contents:
        inline: |
          # Configuration created by matchbox wrapped with Enjoliver
          # Mainly by the ~/app/configs.yaml, ~/app/configs.py, ~/app/sync.py
          # Retrieve the current configuration by calling the following URL:
          # curl '{{.api_uri}}/metadata?{{.request.raw_query}}' | sort
          API_URI='{{.api_uri}}'
          CNI='{{.cni}}'
          CNI_IMAGE_URL='{{.cni_image_url}}'
          DNS_ATTR_DC='{{.dns_attr.dc}}'
          DNS_ATTR_DOMAIN='{{.dns_attr.domain}}'
          DNS_ATTR_POS='{{.dns_attr.pos}}'
          DNS_ATTR_RACK='{{.dns_attr.rack}}'
          DNS_ATTR_SHORTNAME='{{.dns_attr.shortname}}'
          ETCD_IMAGE_URL='{{.etcd_image_url}}'
          ETCD_NAME='{{.etcd_name}}'
          FLEET_ETCD_ADVERTISE_CLIENT_URLS='{{.fleet_etcd_advertise_client_urls}}'
          FLEET_ETCD_CLIENT_PORT='{{.fleet_etcd_client_port}}'
          FLEET_ETCD_DATA_DIR='{{.fleet_etcd_data_dir}}'
          FLEET_ETCD_INITIAL_ADVERTISE_PEER_URLS='{{.fleet_etcd_initial_advertise_peer_urls}}'
          FLEET_ETCD_INITIAL_CLUSTER='{{.fleet_etcd_initial_cluster}}'
          FLEET_ETCD_MEMBER_CLIENT_URI_LIST='{{.fleet_etcd_member_client_uri_list}}'
          FLEET_IMAGE_URL='{{.fleet_image_url}}'
          HOSTNAME='{{.hostname}}'
          HYPERKUBE_IMAGE_URL='{{.hyperkube_image_url}}'
          KUBERNETES_API_SERVER_PORT='{{.kubernetes_apiserver_insecure_port}}'
          KUBERNETES_ETCD_ADVERTISE_CLIENT_URLS='{{.kubernetes_etcd_advertise_client_urls}}'
          KUBERNETES_ETCD_CLIENT_PORT='{{.kubernetes_etcd_client_port}}'
          KUBERNETES_ETCD_DATA_DIR='{{.kubernetes_etcd_data_dir}}'
          KUBERNETES_ETCD_INITIAL_ADVERTISE_PEER_URLS='{{.kubernetes_etcd_initial_advertise_peer_urls}}'
          KUBERNETES_ETCD_INITIAL_CLUSTER='{{.kubernetes_etcd_initial_cluster}}'
          KUBERNETES_ETCD_MEMBER_CLIENT_URI_LIST='{{.kubernetes_etcd_member_client_uri_list}}'
          KUBERNETES_NODE_IP='{{.kubernetes_node_ip}}'
          KUBERNETES_NODE_NAME='{{.kubernetes_node_name}}'
          KUBERNETES_SERVICE_CLUSTER_IP_RANGE='{{.kubernetes_service_cluster_ip_range}}'
          MAC='{{.mac}}'
          NETWORK_CIDRV4='{{.network.cidrv4}}'
          NETWORK_GATEWAY='{{.network.gateway}}'
          NETWORK_IP='{{.network.ip}}'
          REQUEST_QUERY_MAC='{{.request.query.mac}}'
          REQUEST_QUERY_UUID='{{.request.query.uuid}}'
          REQUEST_RAW_QUERY='{{.request.raw_query}}'
          RKT_IMAGE_URL='{{.rkt_image_url}}'
          ROLES='{{.roles}}'
          SELECTOR_MAC='{{.selector.mac}}'

    - path: /etc/hostname
      filesystem: root
      mode: 0644
      contents:
        inline: |
          {{.hostname}}

    - path: /etc/rkt/paths.d/paths.json
      filesystem: root
      mode: 0644
      contents:
        inline: |
          {
            "rktKind": "paths",
            "rktVersion": "v1",
            "stage1-images": "/opt/rootfs/usr/lib/rkt/stage1-images"
          }

    - path: /etc/rkt/stage1.d/coreos.json
      filesystem: root
      mode: 0644
      contents:
        inline: |
          {
              "rktKind": "stage1",
              "rktVersion": "v1",
              "name": "coreos.com/rkt/stage1-coreos",
              "version": "v1.25.0",
              "location": "/opt/rootfs/usr/lib/rkt/stage1-images/stage1-coreos.aci"
          }

    - path: /etc/rkt/net.d/10-k8s.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          {
            "name": "bond0",
            "type": "macvlan",
            "master": "bond0",
            "ipam": {{ .cni }}
          }

    - path: /etc/fleet/fleet.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          etcd_servers = [ http://127.0.0.1:{{.fleet_etcd_client_port}},{{ .fleet_etcd_member_client_uri_list }} ]
          metadata = "name={{.dns_attr.shortname}},diskProfile={{.disk_profile}}"
          etcd_cafile=/etc/vault.d/etcd-fleet/client.issuing_ca
          etcd_certfile=/etc/vault.d/etcd-fleet/client.certificate
          etcd_keyfile=/etc/vault.d/etcd-fleet/client.private_key
          agent_ttl = 120s
          engine_reconcile_interval = 1
          etcd_request_timeout = 10
          disable_engine = true

    - path: /etc/modprobe.d/bonding.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          options bonding mode=1 miimon=100

    - path: /etc/hosts
      mode: 0644
      filesystem: root
      contents:
        inline: |
          127.0.0.1	localhost
          {{ if index . "etc_hosts" }}
          {{ range $element := .etc_hosts }}
          {{$element}}
          {{end}}
          {{end}}

    - path: /etc/coreos/update.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          GROUP=stable
          REBOOT_STRATEGY=off

    - path: /etc/systemd/timesyncd.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          [Time]
          NTP={{.ntp}}
          FallbackNTP={{.fallbackntp}}

    - path: /etc/systemd/resolved.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          [Resolve]
          DNS={{.nameservers}}
          LLMNR=false

    - path: /var/log/journal/.keep
      mode: 0644
      filesystem: root

    - path: /etc/etcd-fleet.env
      mode: 0644
      filesystem: root
      contents:
        inline: |
          ETCD_NAME={{.etcd_name}}
          ETCD_PROXY=on
          ETCD_INITIAL_CLUSTER={{.fleet_etcd_initial_cluster}}
          ETCD_ADVERTISE_CLIENT_URLS=https://{{.network.ip}}:{{.fleet_etcd_client_port}}
          ETCD_MEMBER_CLIENT_URI_LIST={{.fleet_etcd_member_client_uri_list}}
          ETCD_DATA_DIR={{.fleet_etcd_data_dir}}
          ETCD_LISTEN_CLIENT_URLS="http://127.0.0.1:{{.fleet_etcd_client_port}},https://{{.network.ip}}:{{.fleet_etcd_client_port}},http://{{.network.ip}}:2379"

    - path: /opt/bin/etcdctl3
      filesystem: root
      mode: 0544
      contents:
        inline: |
          #!/bin/bash
          ETCDCTL_API=3 exec /opt/bin/etcdctl $@

    - path: /etc/profile.d/common.sh
      mode: 0755
      filesystem: root
      contents:
        inline: |
           export PATH=/opt/bin:$PATH
           export PRIVATE_IPV4={{.network.ip}}

    - path: /etc/modules-load.d/network.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          ip_tables
          iptable_nat
          nf_nat

    - path: /opt/bin/lifecycle-update
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          set -e
          set -o pipefail

          STATUS=$(curl -f -XPOST "{{.api_uri}}/lifecycle/ignition/{{.request.raw_query}}" \
                -d @/usr/share/oem/coreos-install.json \
                -H "Content-Type: application/json" \
                -w "%{http_code}" -o /dev/null)

          set +e
          if [ ${STATUS} -ne 210 ]
          then
              PRESET=/run/systemd-preset-all
              echo "Checking if preset on hold"
              grep -c "^Created symlink" ${PRESET}
              if [ $? -ne 0 ]
              then
                echo "Nothing to do: ${STATUS}, no preset in ${PRESET}"
                exit 0
              fi
              cat ${PRESET} || {
                echo "Nothing to do: ${STATUS}, no file preset ${PRESET}"
                exit 0
              }
          fi

          set -xe

          curl -f "{{.api_uri}}/ignition?{{.request.raw_query}}" -o /tmp/coreos-install.json
          cat /tmp/coreos-install.json | jq -e . > /dev/null

          STRATEGY=$(curl -f "{{.api_uri}}/lifecycle/rolling/{{.request.raw_query}}" | jq -re .strategy ) || {
            exit 0
          }

          echo "Update enable by strategy: ${STRATEGY}"

          echo "locksmithctl operations..."
          locksmithctl -endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} status
          locksmithctl -endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} unlock "{{.request.raw_query}}" || true
          locksmithctl -endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} lock "{{.request.raw_query}}"

          echo "stopping fleet..."
          systemctl stop fleet.service

          echo "draining node..."
          /opt/bin/kubectl -s http://127.0.0.1:{{.kubernetes_apiserver_insecure_port}} \
            drain {{.kubernetes_node_name}} --force --ignore-daemonsets --delete-local-data

          set +e
          for service in kubelet kube-apiserver etcd3@kubernetes etcd3@fleet
          do
            systemctl stop ${service}.service
          done

          /opt/bin/rkt gc --grace-period=0s
          /opt/bin/rkt image gc --grace-period=0s
          rm -Rf /opt/rootfs/*
          set -e

          DEVICE=/dev/sda
          DISK_GUID="00000000-0000-0000-0000-000000000001"
          sgdisk --disk-guid=${DISK_GUID} ${DEVICE}
          cgpt show -v ${DEVICE} | grep -c ${DISK_GUID}

          if [ ${STRATEGY} == "kexec" ]
          then
            kexec --reuse-cmdline \
                  --append="coreos.first_boot=1 coreos.randomize_disk_guid=${DISK_GUID}" \
                  -l /usr/boot/vmlinuz
          fi

          cp -v /tmp/coreos-install.json /usr/share/oem/coreos-install.json

          systemctl ${STRATEGY}


    - path: /opt/bin/lifecycle-ready
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash
          export PATH=/opt/rootfs/usr/bin:/opt/bin/:${PATH}

          set -o pipefail

          function retry {
            until $@
            do
              echo "waiting for $@"
              sleep 1
            done
          }

          retry etcdctl3 \
             --cert=/etc/vault.d/etcd-kubernetes/client.certificate \
             --key=/etc/vault.d/etcd-kubernetes/client.private_key \
             --cacert=/etc/vault.d/etcd-kubernetes/client.issuing_ca \
             --endpoints https://127.0.0.1:{{.kubernetes_etcd_client_port}} endpoint status

          retry etcdctl \
             --cert-file /etc/vault.d/etcd-fleet/client.certificate \
             --key-file /etc/vault.d/etcd-fleet/client.private_key \
             --ca-file /etc/vault.d/etcd-fleet/client.issuing_ca \
             --endpoints http://127.0.0.1:{{.fleet_etcd_client_port}} cluster-health

          retry kubectl -s http://127.0.0.1:{{.kubernetes_apiserver_insecure_port}} cluster-info

          retry curl -fs http://127.0.0.1:10248/healthz

          retry fleetctl --endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} \
            --driver etcd list-machines \
            --fields ip --no-legend | grep -c {{.network.ip}}

          retry fleetctl \
            --ca-file /etc/vault.d/etcd-fleet/client.issuing_ca \
            --cert-file /etc/vault.d/etcd-fleet/client.certificate \
            --key-file /etc/vault.d/etcd-fleet/client.private_key \
            --driver etcd --endpoint https://{{.network.ip}}:{{.fleet_etcd_client_port}},{{.fleet_etcd_member_client_uri_list}} \
            list-machines --fields ip --no-legend | grep -c {{.network.ip}}

          retry kubectl -s http://127.0.0.1:{{.kubernetes_apiserver_insecure_port}} uncordon {{.kubernetes_node_name}}

          systemctl preset-all 2>&1 | tee -a /run/systemd-preset-all

          set -e

          echo "remove the lock"
          locksmithctl -endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} unlock "{{.request.raw_query}}" || true
          echo "$(hostname) {{.network.ip}} is ready"

    - path: /opt/bin/vault-token
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          export PATH=/opt/bin:${PATH}
          set -o pipefail

          test ${1} || {
            echo 'missing $1 eg: etcd-kubernetes'
            exit 2
          }
          test ${2} || {
            echo 'missing $2 eg: peer'
            exit 2
          }

          while true
          do
            for ve in $(echo -n {{ .vault_etcd_member_client_uri_list }} | tr ',' '\n' | shuf)
            do
              REQ="${ve}/v2/keys/token/${1}/${2}"
              echo ${REQ}

              TOKEN=$(curl --insecure -fL ${REQ} | jq -re .node.value)
              if [ $? -eq 0 ]
              then
                echo "TOKEN=${TOKEN}" > /etc/vault.d/${1}/${2}.new

                cmp /etc/vault.d/${1}/${2}.token /etc/vault.d/${1}/${2}.new
                if [ $? -eq 0 ]
                then
                  echo "/etc/vault.d/${1}/${2}.token is up-to-date"
                  exit 0
                else
                  mv -v /etc/vault.d/${1}/${2}.new /etc/vault.d/${1}/${2}.token
                  exit 0
                fi
              fi
            done
            sleep 5
          done

    - path: /opt/bin/vault-fetch-ca
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          export PATH=/opt/bin:${PATH}
          export VAULT_CAPATH=/etc/vault.d/vault/server.issuing_ca
          set -o pipefail

          # TODO consul-template or check if renew
          test -s ${VAULT_CAPATH} || {
          for ve in $(echo -n {{ .vault_ip_list }} | tr ',' '\n' | shuf)
          do
              REQ=https://${ve}:{{.vault_etcd_client_port}}/v2/keys/pki/vault/server.issuing_ca
              echo "GET ${REQ}"
              curl -fs --insecure ${REQ} \
                | jq -re .node.value > ${VAULT_CAPATH} && {
                  ln -svf ${VAULT_CAPATH} /etc/ssl/certs/vault
                  ls -l ${VAULT_CAPATH} /etc/ssl/certs/vault
                  exit $?
              }
              sleep 5
          done
          }
          exit 2

    - path: /opt/bin/vault-pki-issue
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          export PATH=/opt/bin:${PATH}
          export VAULT_CAPATH=/etc/vault.d/vault/server.issuing_ca
          set -o pipefail

          test ${1} || {
            echo 'missing $1 eg: etcd-kubernetes'
            exit 2
          }
          test ${2} || {
            echo 'missing $2 eg: peer'
            exit 2
          }
          test ${TOKEN} || {
            echo 'missing ${TOKEN}'
            exit 2
          }

          # TODO consul-template or check if renew
          test -s /etc/vault.d/${1}/${2}-pki.json && exit 0
          test -s ${VAULT_CAPATH} || {
            /opt/bin/vault-fetch-ca || exit $?
          }

          while true
          do
            for ve in $(echo -n {{ .vault_ip_list }} | tr ',' '\n' | shuf)
            do
              REQ="https://${ve}:8200/v1/pki/${1}/issue/${2}"
              echo "POST ${REQ}"
              curl ${REQ} \
                --cacert ${VAULT_CAPATH} -Lfs \
                --header "X-Vault-Token: ${TOKEN}" \
                -XPOST --data '{
                  "common_name": "{{.network.ip}}",
                  "ttl": "17520h",
                  "ip_sans": "{{.network.ip}},127.0.0.1"
                }' > /etc/vault.d/${1}/${2}-pki.json
              if [ $? -eq 0 ]
              then
                for item in certificate issuing_ca private_key
                do
                  jq -re .data.${item} /etc/vault.d/${1}/${2}-pki.json > /etc/vault.d/${1}/${2}.${item} || exit 2
                done
                exit 0
              fi
            done
            sleep 5
          done

    - path: /opt/bin/vault-secret
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          export PATH=/opt/bin:${PATH}
          export VAULT_CAPATH=/etc/vault.d/vault/server.issuing_ca
          set -o pipefail

          test ${1} || {
            echo 'missing $1 eg: kubernetes'
            exit 2
          }
          test ${2} || {
            echo 'missing $2 eg: service-accounts'
            exit 2
          }
          test ${TOKEN} || {
            echo 'missing ${TOKEN}'
            exit 2
          }

          # TODO consul-template or check if renew
          test -s /etc/vault.d/${1}/${2}-secret.json && exit 0
          test -s ${VAULT_CAPATH} || {
            /opt/bin/vault-fetch-ca || exit $?
          }

          while true
          do
            for ve in $(echo -n {{ .vault_ip_list }} | tr ',' '\n' | shuf)
            do
              REQ="https://${ve}:8200/v1/secret/${1}/${2}"
              echo "GET ${REQ}"
              curl ${REQ} -Lfs \
                --cacert ${VAULT_CAPATH} \
                --header "X-Vault-Token: ${TOKEN}" > /etc/vault.d/${1}/${2}-secret.json
              if [ $? -eq 0 ]
              then
                for item in key
                do
                  jq -re .data.${item} /etc/vault.d/${1}/${2}-secret.json > /etc/vault.d/${1}/${2}.${item} || exit 2
                done
                exit 0
              fi
            done
            sleep 5
          done

    - path: /etc/vault.d/vault/.keep
      mode: 0600
      filesystem: root

    - path: /etc/profile.d/alias.sh
      mode: 0755
      filesystem: root
      contents:
        inline: |
          if [[ $- != *i* ]] ; then
                   return
          fi
          alias ls='ls --color=auto'
          alias la='ls -la'
          alias ll='ls -ll'

networkd:
  units:
    - name: 00-bond0.netdev
      contents: |
        [NetDev]
        Name=bond0
        Kind=bond

    - name: 00-vbond0.netdev
      contents: |
        [NetDev]
        Name=vbond0
        Kind=macvlan
        [MACVLAN]
        Mode=bridge

    - name: 01-ethernet.network
      contents: |
        [Match]
        Name=en*
        [Network]
        Bond=bond0
        LLMNR=false

    - name: 02-ethernet.network
      contents: |
        [Match]
        Name=eth*
        [Network]
        Bond=bond0
        LLMNR=false

    - name: 02-bond0.network
      contents: |
        [Match]
        Name=bond0
        [Network]
        MACVLAN=vbond0
        LLMNR=false

    - name: 03-vbond0.network
      contents: |
        [Match]
        Name=vbond0
        [Network]
        Address={{.network.cidrv4}}
        Gateway={{.network.gateway}}
        LLMNR=false


{{ if index . "ssh_authorized_keys" }}
passwd:
  users:
    - name: core
      ssh_authorized_keys:
        {{ range $element := .ssh_authorized_keys }}
        - {{$element}}
        {{end}}
{{end}}