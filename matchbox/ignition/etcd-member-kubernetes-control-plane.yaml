---
systemd:
  units:
    - name: docker.service
      enable: false
      mask: true

    - name: containerd.service
      enable: false
      mask: true

    - name: update-engine.service
      enable: false
      mask: true

    - name: update-engine-stub.service
      enable: false
      mask: true

    - name: clean-cni.service
      enable: true
      contents: |
        [Unit]
        ConditionDirectoryNotEmpty=/var/lib/cni/networks/bond0
        RefuseManualStart=true
        [Service]
        Type=oneshot
        ExecStart=/bin/rm -Rf /var/lib/cni/networks/bond0
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-etcd.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/etcd
        [Service]
        Type=oneshot
        Environment=IMAGE={{.etcd_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/etcdctl /opt/bin/etcdctl
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/etcd
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-vault.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/vault
        [Service]
        Type=oneshot
        Environment=IMAGE={{.vault_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/vault /opt/bin/vault
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/vault
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-fleet.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/fleetd
        [Service]
        Type=oneshot
        Environment=IMAGE={{.fleet_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/fleetctl /opt/bin/fleetctl
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/fleetd
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-rkt.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/rkt
        [Service]
        Type=oneshot
        Environment=IMAGE={{.rkt_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/rkt /opt/bin/rkt
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/rkt
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-cni.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/usr/bin/host-local
        [Service]
        Type=oneshot
        Environment=IMAGE={{.cni_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/rkt image rm $IMAGE
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/usr/bin/cnitool /opt/bin/cnitool
        ExecReload=-/bin/rm -v /opt/rootfs/usr/bin/host-local
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: install-hyperkube.service
      enable: true
      contents: |
        [Unit]
        Requires=network-online.target
        After=network-online.target
        AssertFileIsExecutable=!/opt/rootfs/hyperkube
        [Service]
        Type=oneshot
        Environment=IMAGE={{.hyperkube_image_url}}
        ExecStartPre=/usr/bin/rkt fetch --insecure-options=all $IMAGE
        ExecStartPre=/usr/bin/rkt image export $IMAGE /tmp/%p.aci
        ExecStartPre=/usr/bin/tar -C /opt/rootfs -xvf /tmp/%p.aci --strip-components=1
        ExecStartPre=/bin/rm -v /tmp/%p.aci

        ExecStart=/usr/bin/ln -sfv /opt/rootfs/hyperkube /opt/bin/kubectl
        ExecReload=-/bin/rm -v /opt/rootfs/hyperkube
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: installs.target
      contents: |
        [Unit]
        Requires=install-cni.service
        After=install-cni.service
        Requires=install-fleet.service
        After=install-fleet.service
        Requires=install-etcd.service
        After=install-etcd.service
        Requires=install-vault.service
        After=install-vault.service
        Requires=install-rkt.service
        After=install-rkt.service
        Requires=install-hyperkube.service
        After=install-hyperkube.service

    - name: rkt-api.service
      enable: true
      contents: |
        [Unit]
        After=install-rkt.service

        [Service]
        ExecStart=/opt/rootfs/usr/bin/rkt api-service
        Restart=always
        RestartSec=10

        [Install]
        RequiredBy=multi-user.target

    - name: systemd-timesyncd.service
      mask: true
      enable: false

    - name: ntpd.service
      enable: true

    - name: etcd-operator@vault.service
      enable: true
      contents: |
        [Unit]
        After=install-etcd.service

        [Service]
        EnvironmentFile=/etc/etcd-%i
        Environment=ETCD_ENV_FILE=/etc/etcd-%i.env
        ExecStart=/opt/bin/etcd-operator
        RestartSec=15s
        Restart=on-failure

        [Install]
        RequiredBy=multi-user.target

    - name: etcd-operator@kubernetes.service
      enable: true
      contents: |
        [Unit]
        After=install-etcd.service

        [Service]
        EnvironmentFile=/etc/etcd-%i
        Environment=ETCD_ENV_FILE=/etc/etcd-%i.env
        ExecStart=/opt/bin/etcd-operator
        RestartSec=15s
        Restart=on-failure

        [Install]
        RequiredBy=multi-user.target

    - name: etcd-operator@fleet.service
      enable: true
      contents: |
        [Unit]
        After=install-etcd.service

        [Service]
        EnvironmentFile=/etc/etcd-%i
        Environment=ETCD_ENV_FILE=/etc/etcd-%i.env
        ExecStart=/opt/bin/etcd-operator
        RestartSec=15s
        Restart=on-failure

        [Install]
        RequiredBy=multi-user.target

    - name: etcd.service
      mask: true
      enable: false

    - name: etcd2.service
      mask: true
      enable: false

    - name: etcd3@vault.service
      enable: true
      contents: |
        [Unit]
        After=install-etcd.service
        Conflicts=etcd.service etcd2.service

        After=etcd-operator@%i.service

        [Service]
        Type=notify
        EnvironmentFile=/etc/etcd-%i.env
        ExecStart=/opt/rootfs/usr/bin/etcd --auto-tls --peer-auto-tls
        RestartSec=15s
        Restart=on-failure
        LimitNOFILE=65826
        [Install]
        WantedBy=multi-user.target

    - name: vault.service
      enable: true
      contents: |
        [Unit]
        After=install-vault.service
        After=etcd3@vault.service
        [Service]
        ExecStartPre=/opt/bin/etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} ls
        ExecStartPre=/opt/bin/vault-config
        ExecStart=/opt/rootfs/usr/bin/vault server -config=/etc/vault.d/
        Restart=always
        RestartSec=5
        [Install]
        WantedBy=multi-user.target

    - name: vault-init.service
      enable: true
      contents: |
        [Unit]
        After=vault.service
        [Service]
        ExecStartPre=/opt/bin/vault version
        ExecStart=/opt/bin/vault-init
        RestartSec=10
        Restart=on-failure
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-server@vault.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i server
        RestartSec=60
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-peer@etcd-kubernetes.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i peer
        RestartSec=60
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-client@etcd-kubernetes.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i client
        RestartSec=60
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-kubelet@kubernetes.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i kubelet
        RestartSec=60
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-kube-apiserver@kubernetes.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i kube-apiserver
        RestartSec=60
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-peer@etcd-fleet.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i peer
        RestartSec=60
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-token-client@etcd-fleet.service
      enable: true
      contents: |
        [Service]
        ExecStartPre=/bin/mkdir -pv /etc/vault.d/%i
        ExecStart=/opt/bin/vault-token %i client
        RestartSec=60
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-server@vault.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/server.token
        ExecStart=/opt/bin/vault-pki-issue %i server
        RestartSec=5
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-peer@etcd-kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/peer.token
        ExecStart=/opt/bin/vault-pki-issue %i peer
        RestartSec=5
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-client@etcd-kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/client.token
        ExecStart=/opt/bin/vault-pki-issue %i client
        RestartSec=5
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-kubelet@kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/kubelet.token
        ExecStart=/opt/bin/vault-pki-issue %i kubelet
        RestartSec=5
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-kube-apiserver@kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/kube-apiserver.token
        ExecStart=/opt/bin/vault-pki-issue %i kube-apiserver
        RestartSec=5
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-secret-service-accounts@kubernetes.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/kube-apiserver.token
        ExecStart=/opt/bin/vault-secret %i service-accounts
        RestartSec=5
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-peer@etcd-fleet.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/peer.token
        ExecStart=/opt/bin/vault-pki-issue %i peer
        RestartSec=5
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: vault-pki-issue-client@etcd-fleet.service
      enable: true
      contents: |
        [Service]
        EnvironmentFile=/etc/vault.d/%i/client.token
        ExecStart=/opt/bin/vault-pki-issue %i client
        RestartSec=5
        Restart=always
        [Install]
        WantedBy=multi-user.target

    - name: etcd3@kubernetes.service
      enable: true
      contents: |
        [Unit]
        After=install-etcd.service
        Conflicts=etcd.service etcd2.service

        After=etcd-operator@%i.service

        [Service]
        Type=notify
        EnvironmentFile=/etc/etcd-%i.env
        ExecStartPre=/bin/ls -l \
          /etc/vault.d/etcd-%i/client.certificate \
          /etc/vault.d/etcd-%i/client.private_key \
          /etc/vault.d/etcd-%i/client.issuing_ca \
          /etc/vault.d/etcd-%i/peer.certificate \
          /etc/vault.d/etcd-%i/peer.private_key \
          /etc/vault.d/etcd-%i/peer.issuing_ca
        ExecStart=/opt/rootfs/usr/bin/etcd \
          --cert-file /etc/vault.d/etcd-%i/client.certificate \
          --key-file /etc/vault.d/etcd-%i/client.private_key \
          --trusted-ca-file /etc/vault.d/etcd-%i/client.issuing_ca \
          --client-cert-auth \
          \
          --peer-cert-file /etc/vault.d/etcd-%i/peer.certificate \
          --peer-key-file /etc/vault.d/etcd-%i/peer.private_key \
          --peer-trusted-ca-file /etc/vault.d/etcd-%i/peer.issuing_ca \
          --peer-client-cert-auth
        RestartSec=20s
        Restart=on-failure
        LimitNOFILE=65826
        [Install]
        WantedBy=multi-user.target

    - name: etcd3@fleet.service
      enable: true
      contents: |
        [Unit]
        After=install-etcd.service
        Conflicts=etcd.service etcd2.service

        After=etcd-operator@%i.service

        [Service]
        Type=notify
        EnvironmentFile=/etc/etcd-%i.env
        ExecStartPre=/bin/ls -l \
          /etc/vault.d/etcd-%i/client.certificate \
          /etc/vault.d/etcd-%i/client.private_key \
          /etc/vault.d/etcd-%i/client.issuing_ca \
          /etc/vault.d/etcd-%i/peer.certificate \
          /etc/vault.d/etcd-%i/peer.private_key \
          /etc/vault.d/etcd-%i/peer.issuing_ca
        ExecStart=/opt/rootfs/usr/bin/etcd \
          --cert-file /etc/vault.d/etcd-%i/client.certificate \
          --key-file /etc/vault.d/etcd-%i/client.private_key \
          --trusted-ca-file /etc/vault.d/etcd-%i/client.issuing_ca \
          --client-cert-auth \
          \
          --peer-cert-file /etc/vault.d/etcd-%i/peer.certificate \
          --peer-key-file /etc/vault.d/etcd-%i/peer.private_key \
          --peer-trusted-ca-file /etc/vault.d/etcd-%i/peer.issuing_ca \
          --peer-client-cert-auth
        RestartSec=15s
        Restart=on-failure
        LimitNOFILE=65826
        [Install]
        WantedBy=multi-user.target

    - name: kubelet.service
      enable: true
      contents: |
        [Unit]
        After=rkt-api.service
        After=etcd3@kubernetes.service
        Requires=rkt-api.service

        [Service]
        EnvironmentFile=/etc/metadata.env
        Environment=MANIFESTS=/etc/kubernetes/manifests
        Environment=ETCDCTL_API=3
        ExecStartPre=/bin/ls -l \
          /etc/vault.d/kubernetes/kubelet.certificate \
          /etc/vault.d/kubernetes/kubelet.private_key \
          /etc/vault.d/kubernetes/kubelet.issuing_ca
        ExecStartPre=/opt/bin/etcdctl --endpoints http://127.0.0.1:{{.kubernetes_etcd_client_port}} endpoint status
        ExecStartPre=/opt/rootfs/usr/bin/rkt fetch --pull-policy=update --insecure-options=all {{.hyperkube_image_url}}
        ExecStartPre=/bin/mkdir -pv /var/lib/kubelet/kubeconfig
        ExecStartPre=/bin/mkdir -pv $MANIFESTS
        ExecStart=/opt/rootfs/hyperkube kubelet \
          \
          --network-plugin=cni \
          --cni-bin-dir=/opt/rootfs/usr/bin \
          --cni-conf-dir=/etc/rkt/net.d \
          \
          --pod-manifest-path=${MANIFESTS} \
          --hostname-override=${KUBERNETES_NODE_NAME} \
          --node-ip=${KUBERNETES_NODE_IP} \
          --register-schedulable=false \
          --allow-privileged=true \
          --enable-custom-metrics \
          --api-servers=http://127.0.0.1:{{.kubernetes_api_server_port}} \
          --node-labels=control-plane=true \
          --cloud-provider="" \
          \
          --container-runtime=rkt \
          --rkt-path=/opt/rootfs/usr/bin/rkt \
          --v=2 \
          --enable-cri=false \
          --tls-cert-file=/etc/vault.d/kubernetes/kubelet.certificate \
          --tls-private-key-file=/etc/vault.d/kubernetes/kubelet.private_key \
          --client-ca-file=/etc/vault.d/kubernetes/kubelet.issuing_ca
        Restart=always
        RestartSec=30s

        [Install]
        WantedBy=multi-user.target

    - name: kube-proxy.service
      enable: true
      contents: |
        [Unit]
        After=kubelet.service

        [Service]
        EnvironmentFile=/etc/metadata.env
        ExecStart=/opt/rootfs/hyperkube proxy \
          --proxy-mode=iptables \
          --hostname-override=${KUBERNETES_NODE_NAME} \
          --master=http://127.0.0.1:8080 \
          --v=2
        Restart=always
        RestartSec=30

        [Install]
        WantedBy=multi-user.target

    - name: fleet.service
      enable: true
      dropins:
        - name: 10-cluster.conf
          contents: |
            [Unit]
            After=installs.target
            After=etcd3@fleet.service
            After=rkt-metadata.service
            [Service]
            EnvironmentFile=/etc/metadata.env
            ExecStartPre=/bin/ls -lL /opt/bin/rkt
            ExecStartPre=/opt/bin/etcdctl --no-sync --endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} ls
            ExecStart=
            ExecStart=/opt/rootfs/usr/bin/fleetd
            Restart=always
            RestartSec=10

    - name: lifecycle-ready.service
      enable: true
      contents: |
        [Unit]
        After=etcd3@kubernetes.service
        After=kubelet.service
        [Service]
        EnvironmentFile=/etc/metadata.env
        Type=oneshot
        ExecStart=/opt/bin/lifecycle-ready
        RemainAfterExit=yes
        [Install]
        WantedBy=multi-user.target

    - name: lifecycle-update.service
      contents: |
        [Unit]
        After=etcd3@kubernetes.service
        After=kubelet.service
        After=lifecycle-ready.service
        [Service]
        EnvironmentFile=/etc/metadata.env
        Type=oneshot
        ExecStart=/opt/bin/lifecycle-update

    - name: lifecycle-update.timer
      enable: true
      contents: |
        [Unit]
        After=etcd3@kubernetes.service
        After=kubelet.service
        After=lifecycle-ready.service
        [Timer]
        OnActiveSec=0s
        OnUnitActiveSec=1m
        [Install]
        WantedBy=default.target


storage:
  files:
    - path: /opt/rootfs/.keep
      filesystem: root
      mode: 0644

    - path: /etc/kubernetes/manifests/kube-apiserver.yaml
      filesystem: root
      contents:
        inline: |
          apiVersion: v1
          kind: Pod
          metadata:
            name: kube-apiserver
            namespace: kube-system
          spec:
            hostNetwork: true
            containers:
            - name: kube-apiserver
              image: {{.hyperkube_image_url}}
              imagePullPolicy: IfNotPresent
              command:
              - /hyperkube
              - apiserver
              - --advertise-address={{.network.ip}}
              - --insecure-bind-address={{.kubernetes_apiserver_insecure_bind_address}}
              - --etcd-servers=http://127.0.0.1:{{.kubernetes_etcd_client_port}}
              - --allow-privileged=true
              - --service-cluster-ip-range={{.kubernetes_service_cluster_ip_range}}
              - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota
              - --runtime-config=batch/v2alpha1
              - --apiserver-count={{.kubernetes_apiserver_count}}
              - --enable-swagger-ui=true
              - --tls-ca-file=/etc/secrets/kube-apiserver.issuing_ca
              - --tls-cert-file=/etc/secrets/kube-apiserver.certificate
              - --tls-private-key-file=/etc/secrets/kube-apiserver.private_key
              - --service-account-key-file=/etc/secrets/service-accounts.key
              - --service-account-lookup=true
              - --runtime-config=rbac.authorization.k8s.io/v1alpha1
              - --authorization-mode=RBAC
              resources:
                requests:
                  cpu: 200m
              livenessProbe:
                httpGet:
                  host: 127.0.0.1
                  port: 8080
                  path: /healthz
                initialDelaySeconds: 15
                timeoutSeconds: 15
              volumeMounts:
              - name: secrets
                mountPath: /etc/secrets
                readOnly: true
            volumes:
            - name: secrets
              hostPath:
                path: /etc/vault.d/kubernetes

    - path: /etc/kubernetes/manifests/kube-controller-manager.yaml
      filesystem: root
      contents:
        inline: |
          apiVersion: v1
          kind: Pod
          metadata:
            name: kube-controller-manager
            namespace: kube-system
          spec:
            hostNetwork: true
            containers:
            - name: kube-controller-manager
              image: {{.hyperkube_image_url}}
              imagePullPolicy: IfNotPresent
              command:
              - /hyperkube
              - controller-manager
              - --master=http://127.0.0.1:{{.kubernetes_api_server_port}}
              - --leader-elect=true
              - --service-account-private-key-file=/etc/secrets/service-accounts.key
              - --cluster-signing-cert-file=/etc/secrets/kube-apiserver.certificate
              - --cluster-signing-key-file=/etc/secrets/kube-apiserver.private_key
              - --root-ca-file=/etc/secrets/kube-apiserver.issuing_ca
              resources:
                requests:
                  cpu: 200m
              livenessProbe:
                httpGet:
                  host: 127.0.0.1
                  path: /healthz
                  port: 10252
                initialDelaySeconds: 15
                timeoutSeconds: 15
              volumeMounts:
              - name: secrets
                mountPath: /etc/secrets
                readOnly: true
            volumes:
            - name: secrets
              hostPath:
                path: /etc/vault.d/kubernetes

    - path: /etc/kubernetes/manifests/kube-scheduler.yaml
      filesystem: root
      contents:
        inline: |
          apiVersion: v1
          kind: Pod
          metadata:
            name: kube-scheduler
            namespace: kube-system
          spec:
            hostNetwork: true
            containers:
            - name: kube-scheduler
              image: {{.hyperkube_image_url}}
              imagePullPolicy: IfNotPresent
              command:
              - /hyperkube
              - scheduler
              - --master=http://127.0.0.1:{{.kubernetes_api_server_port}}
              - --leader-elect=true
              resources:
                requests:
                  cpu: 100m
              livenessProbe:
                httpGet:
                  host: 127.0.0.1
                  path: /healthz
                  port: 10251
                initialDelaySeconds: 15
                timeoutSeconds: 15

    - path: /etc/metadata.env
      filesystem: root
      mode: 0644
      contents:
        inline: |
          # Configuration created by matchbox wrapped with Enjoliver
          # Mainly by the ~/app/configs.yaml, ~/app/configs.py, ~/app/sync.py
          # Retrieve the current configuration by calling the following URL:
          # curl '{{.api_uri}}/metadata?{{.request.raw_query}}' | sort
          API_URI='{{.api_uri}}'
          CNI='{{.cni}}'
          CNI_IMAGE_URL='{{.cni_image_url}}'
          DNS_ATTR_DC='{{.dns_attr.dc}}'
          DNS_ATTR_DOMAIN='{{.dns_attr.domain}}'
          DNS_ATTR_POS='{{.dns_attr.pos}}'
          DNS_ATTR_RACK='{{.dns_attr.rack}}'
          DNS_ATTR_SHORTNAME='{{.dns_attr.shortname}}'
          ETCD_IMAGE_URL='{{.etcd_image_url}}'
          ETCD_NAME='{{.etcd_name}}'
          FLEET_ETCD_ADVERTISE_CLIENT_URLS='{{.fleet_etcd_advertise_client_urls}}'
          FLEET_ETCD_CLIENT_PORT='{{.fleet_etcd_client_port}}'
          FLEET_ETCD_DATA_DIR='{{.fleet_etcd_data_dir}}'
          FLEET_ETCD_INITIAL_ADVERTISE_PEER_URLS='{{.fleet_etcd_initial_advertise_peer_urls}}'
          FLEET_ETCD_INITIAL_CLUSTER='{{.fleet_etcd_initial_cluster}}'
          FLEET_ETCD_MEMBER_CLIENT_URI_LIST='{{.fleet_etcd_member_client_uri_list}}'
          FLEET_ETCD_MEMBER_PEER_URI_LIST='{{.fleet_etcd_member_peer_uri_list}}'
          FLEET_ETCD_PEER_PORT='{{.fleet_etcd_peer_port}}'
          FLEET_IMAGE_URL='{{.fleet_image_url}}'
          HOSTNAME='{{.hostname}}'
          HYPERKUBE_IMAGE_URL='{{.hyperkube_image_url}}'
          KUBERNETES_APISERVER_COUNT='{{.kubernetes_apiserver_count}}'
          KUBERNETES_API_SERVER_PORT='{{.kubernetes_api_server_port}}'
          KUBERNETES_ETCD_ADVERTISE_CLIENT_URLS='{{.kubernetes_etcd_advertise_client_urls}}'
          KUBERNETES_ETCD_CLIENT_PORT='{{.kubernetes_etcd_client_port}}'
          KUBERNETES_ETCD_DATA_DIR='{{.kubernetes_etcd_data_dir}}'
          KUBERNETES_ETCD_INITIAL_ADVERTISE_PEER_URLS='{{.kubernetes_etcd_initial_advertise_peer_urls}}'
          KUBERNETES_ETCD_INITIAL_CLUSTER='{{.kubernetes_etcd_initial_cluster}}'
          KUBERNETES_ETCD_MEMBER_CLIENT_URI_LIST='{{.kubernetes_etcd_member_client_uri_list}}'
          KUBERNETES_ETCD_MEMBER_PEER_URI_LIST='{{.kubernetes_etcd_member_peer_uri_list}}'
          KUBERNETES_ETCD_PEER_PORT='{{.kubernetes_etcd_peer_port}}'
          KUBERNETES_NODE_IP='{{.kubernetes_node_ip}}'
          KUBERNETES_NODE_NAME='{{.kubernetes_node_name}}'
          KUBERNETES_SERVICE_CLUSTER_IP_RANGE='{{.kubernetes_service_cluster_ip_range}}'
          MAC='{{.mac}}'
          NETWORK_CIDRV4='{{.network.cidrv4}}'
          NETWORK_GATEWAY='{{.network.gateway}}'
          NETWORK_IP='{{.network.ip}}'
          REQUEST_QUERY_MAC='{{.request.query.mac}}'
          REQUEST_QUERY_UUID='{{.request.query.uuid}}'
          REQUEST_RAW_QUERY='{{.request.raw_query}}'
          RKT_IMAGE_URL='{{.rkt_image_url}}'
          ROLES='{{.roles}}'
          SELECTOR_MAC='{{.selector.mac}}'
          VAULT_ETCD_ADVERTISE_CLIENT_URLS='{{.fleet_etcd_advertise_client_urls}}'
          VAULT_ETCD_CLIENT_PORT='{{.fleet_etcd_client_port}}'
          VAULT_ETCD_DATA_DIR='{{.fleet_etcd_data_dir}}'
          VAULT_ETCD_INITIAL_ADVERTISE_PEER_URLS='{{.fleet_etcd_initial_advertise_peer_urls}}'
          VAULT_ETCD_INITIAL_CLUSTER='{{.fleet_etcd_initial_cluster}}'
          VAULT_ETCD_MEMBER_CLIENT_URI_LIST='{{.fleet_etcd_member_client_uri_list}}'
          VAULT_ETCD_MEMBER_PEER_URI_LIST='{{.fleet_etcd_member_peer_uri_list}}'
          VAULT_ETCD_PEER_PORT='{{.fleet_etcd_peer_port}}'
          VAULT_ETCD_ADVERTISE_CLIENT_URLS='{{.vault_etcd_advertise_client_urls}}'
          VAULT_ETCD_CLIENT_PORT='{{.vault_etcd_client_port}}'
          VAULT_ETCD_DATA_DIR='{{.vault_etcd_data_dir}}'
          VAULT_ETCD_INITIAL_ADVERTISE_PEER_URLS='{{.vault_etcd_initial_advertise_peer_urls}}'
          VAULT_ETCD_INITIAL_CLUSTER='{{.vault_etcd_initial_cluster}}'
          VAULT_ETCD_MEMBER_CLIENT_URI_LIST='{{.vault_etcd_member_client_uri_list}}'
          VAULT_ETCD_MEMBER_PEER_URI_LIST='{{.vault_etcd_member_peer_uri_list}}'
          VAULT_ETCD_PEER_PORT='{{.vault_etcd_peer_port}}'
          VAULT_IMAGE_URL='{{.vault_image_url}}'

    - path: /etc/hostname
      filesystem: root
      mode: 0644
      contents:
        inline: |
          {{.hostname}}

    - path: /etc/rkt/paths.d/paths.json
      filesystem: root
      mode: 0644
      contents:
        inline: |
          {
            "rktKind": "paths",
            "rktVersion": "v1",
            "stage1-images": "/opt/rootfs/usr/lib/rkt/stage1-images"
          }

    - path: /etc/rkt/stage1.d/coreos.json
      filesystem: root
      mode: 0644
      contents:
        inline: |
          {
              "rktKind": "stage1",
              "rktVersion": "v1",
              "name": "coreos.com/rkt/stage1-coreos",
              "version": "v1.25.0",
              "location": "/opt/rootfs/usr/lib/rkt/stage1-images/stage1-coreos.aci"
          }

    - path: /etc/rkt/net.d/10-k8s.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          {
            "name": "bond0",
            "type": "macvlan",
            "master": "bond0",
            "ipam": {{ .cni }}
          }

    - path: /etc/vault.d/config.hcl.insecure
      filesystem: root
      mode: 0644
      contents:
        inline: |
          storage "etcd" {
            address  = "http://127.0.0.1:{{.vault_etcd_client_port}}"
            etcd_api = "v2"
            sync = "false"
          }
          listener "tcp" {
            address     = "127.0.0.1:8200"
            tls_disable = 1
          }

    - path: /etc/vault.d/config.hcl.secure
      filesystem: root
      mode: 0644
      contents:
        inline: |
          storage "etcd" {
            address  = "http://127.0.0.1:{{.vault_etcd_client_port}}"
            etcd_api = "v2"
            ha_enabled = "true"
            redirect_addr = "https://{{.network.ip}}:8200"
            sync = "false"
          }
          listener "tcp" {
            address     = "{{.network.ip}}:8200"
            tls_cert_file = "/etc/vault.d/vault/server.certificate"
            tls_key_file  = "/etc/vault.d/vault/server.private_key"
          }
          listener "tcp" {
            address     = "127.0.0.1:8200"
            tls_disable = 1
          }

    - path: /etc/fleet/fleet.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          etcd_servers = [ http://127.0.0.1:{{.fleet_etcd_client_port}},{{ .fleet_etcd_member_client_uri_list }} ]
          metadata = "name={{.dns_attr.shortname}}"
          etcd_cafile=/etc/vault.d/etcd-fleet/client.issuing_ca
          etcd_certfile=/etc/vault.d/etcd-fleet/client.certificate
          etcd_keyfile=/etc/vault.d/etcd-fleet/client.private_key

    - path: /etc/modprobe.d/bonding.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          options bonding mode=1 miimon=100

    - path: /etc/hosts
      mode: 0644
      filesystem: root
      contents:
        inline: |
          127.0.0.1	localhost
          {{ if index . "etc_hosts" }}
          {{ range $element := .etc_hosts }}
          {{$element}}
          {{end}}
          {{end}}

    - path: /etc/coreos/update.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          GROUP=stable
          REBOOT_STRATEGY=off

    - path: /etc/systemd/resolved.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          [Resolve]
          DNS=8.8.8.8 8.8.4.4
          LLMNR=false

    - path: /var/log/journal/.keep
      mode: 0644
      filesystem: root

    - path: /etc/etcd-vault
      mode: 0644
      filesystem: root
      contents:
        inline: |
          ETCD_NAME={{.etcd_name}}
          ETCD_INITIAL_CLUSTER={{.vault_etcd_initial_cluster}}
          ETCD_ADVERTISE_CLIENT_URLS="{{.vault_etcd_advertise_client_urls}}"
          ETCD_INITIAL_ADVERTISE_PEER_URLS={{.vault_etcd_initial_advertise_peer_urls}}
          ETCD_MEMBER_CLIENT_URI_LIST={{.vault_etcd_member_client_uri_list}}
          ETCD_MEMBER_PEER_URI_LIST={{.vault_etcd_member_peer_uri_list}}
          ETCD_DATA_DIR={{.vault_etcd_data_dir}}
          ETCD_LISTEN_CLIENT_URLS="http://127.0.0.1:{{.vault_etcd_client_port}},https://{{.network.ip}}:{{.vault_etcd_client_port}}"
          ETCD_LISTEN_PEER_URLS="https://0.0.0.0:{{.vault_etcd_peer_port}}"

          NETWORK_IP={{.network.ip}}
          ETCD_FLAGS="--insecure-transport=false --insecure-skip-tls-verify=true"

    - path: /etc/etcd-kubernetes
      mode: 0644
      filesystem: root
      contents:
        inline: |
          ETCD_NAME={{.etcd_name}}
          ETCD_INITIAL_CLUSTER={{.kubernetes_etcd_initial_cluster}}
          ETCD_ADVERTISE_CLIENT_URLS={{.kubernetes_etcd_advertise_client_urls}}
          ETCD_INITIAL_ADVERTISE_PEER_URLS={{.kubernetes_etcd_initial_advertise_peer_urls}}
          ETCD_MEMBER_CLIENT_URI_LIST={{.kubernetes_etcd_member_client_uri_list}}
          ETCD_MEMBER_PEER_URI_LIST={{.kubernetes_etcd_member_peer_uri_list}}
          ETCD_DATA_DIR={{.kubernetes_etcd_data_dir}}
          ETCD_LISTEN_CLIENT_URLS="http://127.0.0.1:{{.kubernetes_etcd_client_port}},https://{{.network.ip}}:{{.kubernetes_etcd_client_port}}"
          ETCD_LISTEN_PEER_URLS="https://0.0.0.0:{{.kubernetes_etcd_peer_port}}"

          NETWORK_IP={{.network.ip}}
          ETCD_FLAGS="--cert=/etc/vault.d/etcd-kubernetes/client.certificate \
          --key=/etc/vault.d/etcd-kubernetes/client.private_key \
          --cacert=/etc/vault.d/etcd-kubernetes/client.issuing_ca"

    - path: /etc/etcd-fleet
      mode: 0644
      filesystem: root
      contents:
        inline: |
          ETCD_NAME={{.etcd_name}}
          ETCD_INITIAL_CLUSTER={{.fleet_etcd_initial_cluster}}
          ETCD_ADVERTISE_CLIENT_URLS={{.fleet_etcd_advertise_client_urls}}
          ETCD_INITIAL_ADVERTISE_PEER_URLS={{.fleet_etcd_initial_advertise_peer_urls}}
          ETCD_MEMBER_CLIENT_URI_LIST={{.fleet_etcd_member_client_uri_list}}
          ETCD_MEMBER_PEER_URI_LIST={{.fleet_etcd_member_peer_uri_list}}
          ETCD_DATA_DIR={{.fleet_etcd_data_dir}}
          ETCD_LISTEN_CLIENT_URLS="http://127.0.0.1:{{.fleet_etcd_client_port}},https://{{.network.ip}}:{{.fleet_etcd_client_port}}"
          ETCD_LISTEN_PEER_URLS="https://0.0.0.0:{{.fleet_etcd_peer_port}}"

          NETWORK_IP={{.network.ip}}
          ETCD_FLAGS="--cert=/etc/vault.d/etcd-fleet/client.certificate \
          --key=/etc/vault.d/etcd-fleet/client.private_key \
          --cacert=/etc/vault.d/etcd-fleet/client.issuing_ca"


    - path: /opt/bin/etcd-operator
      filesystem: root
      mode: 0544
      contents:
        inline: |
          #!/usr/bin/env bash
          set -o pipefail ; set -ex
          export PATH=/opt/bin/:${PATH}
          export ETCDCTL_API=3

          env | grep "^ETCD"
          echo ${ETCD_ENV_FILE}

          set +e
          # Check if the data-dir is empty: First boot
          if [ ! -d ${ETCD_DATA_DIR}/member ]
          then

              echo "${ETCD_DATA_DIR}/member is empty"
              # Check if there is an existing cluster
              etcdctl ${ETCD_FLAGS} --endpoints ${ETCD_MEMBER_CLIENT_URI_LIST} endpoint status
              RET=$?

              if [ ${RET} -eq 128 ]
              then
                echo "certs in ETCD_FLAGS=${ETCD_FLAGS} unavailables" >&2
                exit 2

              elif [ ${RET} -eq 1 ]
              then
                echo "Existing cluster"
                ETCD_INITIAL_CLUSTER_STATE=existing

                # Check if this new member make a replacement
                REMOVE=$(etcdctl ${ETCD_FLAGS} --endpoints ${ETCD_MEMBER_CLIENT_URI_LIST} member list | \
                  grep {{.network.ip}} | cut -f1 -d ',')

                if [ $REMOVE ]
                then
                  echo "Remove ${REMOVE}"
                  etcdctl ${ETCD_FLAGS} --endpoints ${ETCD_MEMBER_CLIENT_URI_LIST} member remove ${REMOVE}
                fi

                echo "Extend original cluster"
                ETCD_INITIAL_CLUSTER=$(etcdctl ${ETCD_FLAGS} --endpoints ${ETCD_MEMBER_CLIENT_URI_LIST} member add \
                  ${ETCD_NAME} --peer-urls=${ETCD_INITIAL_ADVERTISE_PEER_URLS} | grep "ETCD_INITIAL_CLUSTER=" | \
                  sed 's/ETCD_INITIAL_CLUSTER=//')

                if [ -z $ETCD_INITIAL_CLUSTER ]
                then
                  echo "Fail to extend original cluster: ETCD_INITIAL_CLUSTER=${ETCD_INITIAL_CLUSTER}"
                fi
              else
                ETCD_INITIAL_CLUSTER_STATE=new
                mkdir -pv ${ETCD_DATA_DIR}
              fi

            else
              echo "Already some data in ${ETCD_DATA_DIR}"
              cat ${ETCD_ENV_FILE}
              exit $?
          fi

          set -e

          if [ -z ${ETCD_INITIAL_CLUSTER} ]
          then
              echo '${ETCD_INITIAL_CLUSTER} is empty'
              exit 2
          fi

          cat << EOF | tee ${ETCD_ENV_FILE}
          ETCD_INITIAL_CLUSTER_STATE=$ETCD_INITIAL_CLUSTER_STATE
          ETCD_INITIAL_CLUSTER=$ETCD_INITIAL_CLUSTER
          ETCD_ADVERTISE_CLIENT_URLS=$ETCD_ADVERTISE_CLIENT_URLS
          ETCD_INITIAL_ADVERTISE_PEER_URLS=$ETCD_INITIAL_ADVERTISE_PEER_URLS
          ETCD_LISTEN_CLIENT_URLS=$ETCD_LISTEN_CLIENT_URLS
          ETCD_LISTEN_PEER_URLS=$ETCD_LISTEN_PEER_URLS
          ETCD_NAME=$ETCD_NAME
          ETCD_DATA_DIR=$ETCD_DATA_DIR
          EOF

    - path: /etc/profile.d/path.sh
      mode: 0755
      filesystem: root
      contents:
        inline: |
           export PATH=/opt/bin:$PATH
           export VAULT_ADDR=http://127.0.0.1:8200

    - path: /etc/modules-load.d/network.conf
      mode: 0644
      filesystem: root
      contents:
        inline: |
          ip_tables
          iptable_nat
          nf_nat

    - path: /opt/bin/lifecycle-update
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          set -e

          set -o pipefail

          curl -f ${API_URI}/healthz

          test ${REQUEST_RAW_QUERY}

          STATUS=$(curl -f -XPOST ${API_URI}/lifecycle/ignition/${REQUEST_RAW_QUERY} \
                -d @/usr/share/oem/coreos-install.json \
                -H "Content-Type: application/json" \
                -w "%{http_code}" -o /dev/null)

          if [ ${STATUS} -ne 210 ]
          then
              echo "Nothing to do: ${STATUS}"
              exit 0
          fi

          set -x

          curl -f ${API_URI}/ignition?${REQUEST_RAW_QUERY} -o /tmp/coreos-install.json
          cat /tmp/coreos-install.json | jq -e . > /dev/null

          STRATEGY=$(curl -f ${API_URI}/lifecycle/rolling/${REQUEST_RAW_QUERY} | jq -re .strategy ) || {
            exit 0
          }

          echo "Update enable by strategy: ${STRATEGY}"

          echo "locksmithctl operations..."
          locksmithctl -endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} status
          locksmithctl -endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} unlock "${REQUEST_RAW_QUERY}" || true
          locksmithctl -endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} lock "${REQUEST_RAW_QUERY}"

          echo "stopping fleet..."
          systemctl stop fleet.service

          echo "draining node..."
          /opt/bin/kubectl drain {{.kubernetes_node_name}} --force --ignore-daemonsets --delete-local-data

          DEVICE=/dev/sda
          DISK_GUID="00000000-0000-0000-0000-000000000001"
          sgdisk --disk-guid=${DISK_GUID} ${DEVICE}
          cgpt show -v ${DEVICE} | grep -c ${DISK_GUID}

          rm -Rf /opt/rootfs/* || true

          if [ ${STRATEGY} == "kexec" ]
          then
            kexec --reuse-cmdline \
                  --append="coreos.first_boot=1 coreos.randomize_disk_guid=${DISK_GUID}" \
                  -l /usr/boot/vmlinuz
          fi

          cp -v /tmp/coreos-install.json /usr/share/oem/coreos-install.json

          systemctl ${STRATEGY}


    - path: /opt/bin/lifecycle-ready
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          test "${REQUEST_RAW_QUERY}" || exit 2
          test "${NETWORK_IP}" || exit 2
          export PATH=/opt/rootfs/usr/bin:/opt/bin/:${PATH}

          set -o pipefail

          function retry {
            until $@
            do
              echo "waiting for $@"
              sleep 1
            done
          }

          export ETCDCTL_API=3
          retry etcdctl \
             --insecure-skip-tls-verify=true \
             --insecure-transport=false \
             --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} endpoint status

          retry etcdctl \
             --cert=/etc/vault.d/etcd-kubernetes/client.certificate \
             --key=/etc/vault.d/etcd-kubernetes/client.private_key \
             --cacert=/etc/vault.d/etcd-kubernetes/client.issuing_ca \
             --endpoints http://127.0.0.1:{{.kubernetes_etcd_client_port}} endpoint status

          retry etcdctl \
             --cert=/etc/vault.d/etcd-fleet/client.certificate \
             --key=/etc/vault.d/etcd-fleet/client.private_key \
             --cacert=/etc/vault.d/etcd-fleet/client.issuing_ca \
             --endpoints http://127.0.0.1:{{.fleet_etcd_client_port}} endpoint status

          unset ETCDCTL_API
          retry etcdctl \
             --cert-file /etc/vault.d/etcd-fleet/client.certificate \
             --key-file /etc/vault.d/etcd-fleet/client.private_key \
             --ca-file /etc/vault.d/etcd-fleet/client.issuing_ca \
             --endpoints http://127.0.0.1:{{.fleet_etcd_client_port}} cluster-health

          retry kubectl get cs

          retry curl -fs http://127.0.0.1:10248/healthz

          retry fleetctl --endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} \
            --driver etcd list-machines \
            --fields ip --no-legend | grep -c {{.network.ip}}

          retry fleetctl \
            --ca-file /etc/vault.d/etcd-fleet/client.issuing_ca \
            --cert-file /etc/vault.d/etcd-fleet/client.certificate \
            --key-file /etc/vault.d/etcd-fleet/client.private_key \
            --driver etcd --endpoint {{.fleet_etcd_member_client_uri_list}} list-machines \
            --fields ip --no-legend | grep -c {{.network.ip}}

          retry kubectl uncordon {{.kubernetes_node_name}}

          set -e

          echo "remove the lock"
          locksmithctl -endpoint http://127.0.0.1:{{.fleet_etcd_client_port}} unlock "${REQUEST_RAW_QUERY}" || true
          echo "$(hostname) {{.network.ip}} is ready"

    - path: /opt/bin/vault-config
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          ls -l /etc/vault.d/vault/server.certificate /etc/vault.d/vault/server.private_key || {
            cp -v /etc/vault.d/config.hcl.insecure /etc/vault.d/config.hcl
            exit $?
          }
          cp -v /etc/vault.d/config.hcl.secure /etc/vault.d/config.hcl

    - path: /opt/bin/vault-init
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          export VAULT_ADDR="http://127.0.0.1:8200"
          export PATH=/opt/bin:${PATH}

          vault init -check && {
            curl --insecure https://{{.network.ip}}:8200 || {
              echo "vault already init but not running with TLS"
              sleep 120
              systemctl restart vault
            }
            exit 0
          }
          function retry {
            until $@
            do
              echo "waiting for $@"
              sleep 1
            done
          }

          set -ex
          set -o pipefail

          echo "vault init"
          vault init -key-shares=1 -key-threshold=1 > /etc/vault.d/keys

          UNSEALKEY1=$(cat /etc/vault.d/keys | grep "Unseal Key 1:" | cut -f4 -d ' ')
          ROOTTOKEN=$(cat /etc/vault.d/keys | grep "Initial Root Token:" | cut -f4 -d ' ')

          retry vault unseal ${UNSEALKEY1}
          retry vault auth ${ROOTTOKEN} >> /etc/vault.d/vault.log
          etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} \
            set initier "$(hostname)-${{.network.ip}}"

          echo "create certs for vault himself"
          vault mount -path pki/vault pki
          vault mount-tune -max-lease-ttl=87600h pki/vault
          vault write pki/vault/root/generate/internal common_name=vault ttl=87600h # 10y
          vault write pki/vault/roles/server allow_any_name=true max_ttl=43800h # 2y

          vault policy-write vault/server - << EOF
          path "pki/vault/issue/server" {
            policy = "write"
          }
          EOF

          vault token-create -format=json \
            -display-name vault/server \
            -ttl="8760h" -orphan -period="8760h" \
            -policy="vault/server" | jq -er .auth.client_token | \
              etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} \
                set token/vault/server >> /etc/vault.d/vault.log

          vault write -format=json pki/vault/issue/server \
            ttl=17520h \
            common_name={{.network.ip}} \
            ip_sans={{.network.ip}} \
              > /etc/vault.d/vault/server-pki.json

          for item in certificate issuing_ca private_key
          do
            jq -re .data.${item} /etc/vault.d/vault/server-pki.json > /etc/vault.d/vault/server.${item}
          done

          cat /etc/vault.d/vault/server.issuing_ca | etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} \
            set pki/vault/server.issuing_ca

          systemctl restart vault

          retry vault unseal ${UNSEALKEY1}
          retry vault auth ${ROOTTOKEN} >> /etc/vault.d/vault.log

          echo "init cluster task"
          for ETCD_ROLE in etcd-kubernetes etcd-fleet
          do
            echo "task for ${ETCD_ROLE}"
            vault mount -path pki/${ETCD_ROLE} pki
            vault mount-tune -max-lease-ttl=87600h pki/${ETCD_ROLE}
            vault write pki/${ETCD_ROLE}/root/generate/internal common_name=${ETCD_ROLE} ttl=87600h # 10y
            vault write pki/${ETCD_ROLE}/roles/peer allow_any_name=true max_ttl=43800h # 2y
            vault write pki/${ETCD_ROLE}/roles/client allow_any_name=true max_ttl=43800h # 2y

            vault policy-write ${ETCD_ROLE}/peer - << EOF
            path "pki/${ETCD_ROLE}/issue/peer" {
              policy = "write"
            }
          EOF

            vault policy-write ${ETCD_ROLE}/client - << EOF
            path "pki/${ETCD_ROLE}/issue/client" {
              policy = "write"
            }
          EOF

            vault token-create -format=json \
              -display-name ${ETCD_ROLE}/peer \
              -ttl="8760h" -orphan -period="8760h" \
              -policy="${ETCD_ROLE}/peer" | jq -er .auth.client_token | \
                etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} \
                  set token/${ETCD_ROLE}/peer >> /etc/vault.d/vault.log

            vault token-create -format=json \
              -display-name ${ETCD_ROLE}/client \
              -ttl="8760h" -orphan -period="8760h" \
              -policy="${ETCD_ROLE}/client" | jq -er .auth.client_token | \
                etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} \
                  set token/${ETCD_ROLE}/client >> /etc/vault.d/vault.log
          done

          echo "task for kubernetes"
          openssl genrsa 4096 > /etc/vault.d/service-accounts.rsa
          vault write secret/kubernetes/service-accounts key=@/etc/vault.d/service-accounts.rsa

          vault mount -path pki/kubernetes pki
          vault mount-tune -max-lease-ttl=87600h pki/kubernetes
          vault write pki/kubernetes/root/generate/internal common_name=kubernetes ttl=87600h # 10y
          vault write pki/kubernetes/roles/kube-apiserver allow_any_name=true max_ttl=43800h # 2y
          vault write pki/kubernetes/roles/kubelet allow_any_name=true max_ttl=43800h # 2y
          vault write pki/kubernetes/roles/kubectl allow_any_name=true organization="system:masters" max_ttl=1440h # 60j

          vault policy-write kubernetes/kube-apiserver - << EOF
          path "pki/kubernetes/issue/kube-apiserver" {
            policy = "write"
          }
          path "secret/kubernetes/service-accounts" {
            policy = "read"
          }
          EOF

          vault policy-write kubernetes/kubelet - << EOF
          path "pki/kubernetes/issue/kubelet" {
            policy = "write"
          }
          EOF

          vault policy-write kubernetes/kubectl - << EOF
          path "pki/kubernetes/issue/kubectl" {
            policy = "write"
          }
          EOF

          vault token-create -format=json \
            -display-name kubernetes/kube-apiserver \
            -ttl="8760h" -orphan -period="8760h" \
            -policy="kubernetes/kube-apiserver" | jq -er .auth.client_token | \
              etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} \
                set token/kubernetes/kube-apiserver >> /etc/vault.d/vault.log

          vault token-create -format=json \
            -display-name kubernetes/kubelet \
            -ttl="8760h" -orphan -period="8760h" \
            -policy="kubernetes/kubelet" | jq -er .auth.client_token | \
              etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} \
                set token/kubernetes/kubelet >> /etc/vault.d/vault.log

          vault token-create -format=json \
            -display-name kubernetes/kubectl \
            -ttl="8760h" -orphan -period="8760h" \
            -policy="kubernetes/kubectl" | jq -er .auth.client_token | \
              etcdctl --no-sync --endpoints http://127.0.0.1:{{.vault_etcd_client_port}} \
                set token/kubernetes/kubectl >> /etc/vault.d/vault.log

    - path: /opt/bin/vault-token
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          export PATH=/opt/bin:${PATH}
          set -o pipefail

          test ${1} || {
            echo 'missing $1 eg: etcd-kubernetes'
            exit 2
          }
          test ${2} || {
            echo 'missing $2 eg: peer'
            exit 2
          }

          while true
          do
            for ve in $(echo -n {{ .vault_etcd_member_client_uri_list }} | tr ',' ' ')
            do
              REQ="${ve}/v2/keys/token/${1}/${2}"
              echo ${REQ}

              TOKEN=$(curl --insecure -fL ${REQ} | jq -re .node.value)
              if [ $? -eq 0 ]
              then
                echo "TOKEN=${TOKEN}" > /etc/vault.d/${1}/${2}.new

                cmp /etc/vault.d/${1}/${2}.token /etc/vault.d/${1}/${2}.new
                if [ $? -eq 0 ]
                then
                  echo "/etc/vault.d/${1}/${2}.token is up-to-date"
                  exit 0
                else
                  mv -v /etc/vault.d/${1}/${2}.new /etc/vault.d/${1}/${2}.token
                  exit 0
                fi
              fi
            done
            sleep 5
          done

    - path: /opt/bin/vault-pki-issue
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          export PATH=/opt/bin:${PATH}
          export VAULT_CAPATH=/etc/vault.d/vault/server.issuing_ca
          set -o pipefail

          test ${1} || {
            echo 'missing $1 eg: etcd-kubernetes'
            exit 2
          }
          test ${2} || {
            echo 'missing $2 eg: peer'
            exit 2
          }
          test ${TOKEN} || {
            echo 'missing ${TOKEN}'
            exit 2
          }

          # TODO consul-template or check if renew
          test -f /etc/vault.d/${1}/${2}-pki.json && exit 0
          test -f ${VAULT_CAPATH} || {
          for ve in $(echo -n {{ .vault_ip_list }} | tr ',' ' ')
          do
           curl -f --insecure https://${ve}:{{.vault_etcd_client_port}}/v2/keys/pki/vault/server.issuing_ca \
             | jq -re .node.value > ${VAULT_CAPATH} && {
             ln -svf ${VAULT_CAPATH} /etc/ssl/certs/vault
             break
             }
          done
          }

          while true
          do
            for ve in $(echo -n {{ .vault_ip_list }} | tr ',' ' ')
            do
              curl https://${ve}:8200/v1/pki/${1}/issue/${2} \
                --cacert ${VAULT_CAPATH} -Lf \
                --header "X-Vault-Token: ${TOKEN}" \
                -XPOST --data '{
                  "common_name": "{{.network.ip}}",
                  "ttl": "17520h",
                  "ip_sans": "{{.network.ip}}"
                }' > /etc/vault.d/${1}/${2}-pki.json
              if [ $? -eq 0 ]
              then
                for item in certificate issuing_ca private_key
                do
                  jq -re .data.${item} /etc/vault.d/${1}/${2}-pki.json > /etc/vault.d/${1}/${2}.${item}  || continue
                done
                exit 0
              fi
            done
            sleep 5
          done

    - path: /opt/bin/vault-secret
      mode: 0544
      filesystem: root
      contents:
        inline: |
          #!/usr/bin/env bash

          export PATH=/opt/bin:${PATH}
          export VAULT_CAPATH=/etc/vault.d/vault/server.issuing_ca
          set -o pipefail

          test ${1} || {
            echo 'missing $1 eg: kubernetes'
            exit 2
          }
          test ${2} || {
            echo 'missing $2 eg: service-accounts'
            exit 2
          }
          test ${TOKEN} || {
            echo 'missing ${TOKEN}'
            exit 2
          }

          # TODO consul-template or check if renew
          test -f /etc/vault.d/${1}/${2}-secret.json && exit 0
          test -f ${VAULT_CAPATH} || {
          for ve in $(echo -n {{ .vault_ip_list }} | tr ',' ' ')
          do
            curl -f --insecure https://${ve}:{{.vault_etcd_client_port}}/v2/keys/pki/vault/server.issuing_ca \
              | jq -re .node.value > ${VAULT_CAPATH} && {
             ln -svf ${VAULT_CAPATH} /etc/ssl/certs/vault
             break
             }
          done
          }

          while true
          do
            for ve in $(echo -n {{ .vault_ip_list }} | tr ',' ' ')
            do
              REQ="https://${ve}:8200/v1/secret/${1}/${2}"
              echo ${REQ}
              curl ${REQ} -Lf \
                --cacert ${VAULT_CAPATH} \
                --header "X-Vault-Token: ${TOKEN}" > /etc/vault.d/${1}/${2}-secret.json
              if [ $? -eq 0 ]
              then
                for item in key
                do
                  jq -re .data.${item} /etc/vault.d/${1}/${2}-secret.json > /etc/vault.d/${1}/${2}.${item} || continue
                done
                exit 0
              fi
            done
            sleep 5
          done

    - path: /etc/vault.d/vault/.keep
      mode: 0600
      filesystem: root

networkd:
  units:
    - name: 00-bond0.netdev
      contents: |
        [NetDev]
        Name=bond0
        Kind=bond

    - name: 00-vbond0.netdev
      contents: |
        [NetDev]
        Name=vbond0
        Kind=macvlan
        [MACVLAN]
        Mode=bridge

    - name: 01-ethernet.network
      contents: |
        [Match]
        Name=en*
        [Network]
        Bond=bond0
        LLMNR=false

    - name: 02-ethernet.network
      contents: |
        [Match]
        Name=eth*
        [Network]
        Bond=bond0
        LLMNR=false

    - name: 02-bond0.network
      contents: |
        [Match]
        Name=bond0
        [Network]
        MACVLAN=vbond0
        LLMNR=false

    - name: 03-vbond0.network
      contents: |
        [Match]
        Name=vbond0
        [Network]
        Address={{.network.cidrv4}}
        Gateway={{.network.gateway}}
        LLMNR=false


{{ if index . "ssh_authorized_keys" }}
passwd:
  users:
    - name: core
      ssh_authorized_keys:
        {{ range $element := .ssh_authorized_keys }}
        - {{$element}}
        {{end}}
{{end}}